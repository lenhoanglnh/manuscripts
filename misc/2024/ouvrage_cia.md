# Trois questions philosophiques sur la démocratie numérique

« Le niveau de démocratie dont jouit le citoyen moyen dans le monde en 2023 
est retombé à son niveau de 1985 », 
peut-on lire dans le rapport 2024 du V-Dem Institute.
« Les déclins de la démocratie continuent d'être plus nombreux que les progrès »,
ajoute l'analyse 2024 du Global State of Democracy Initative,
un institut intergouvernemental associé à l'Organisation des Nations Unies.
Depuis une décennie en particulier,
les démocraties sont de plus en plus confrontées à des dérives autoritaires et populistes,
alimentées par la désinformation et la haine.

S'ils ne sont pas les seuls responsables,
les réseaux sociaux ont été souvent identifiés
comme l'une des sources majeures de l'amplification de ces dérives 
(Tufekci 2017, Aral 2020, Chavalarias 2022).
L'élément à charge le plus compromettant nous vient peut-être des *Facebook Files*,
des documents internes à l'entreprise Facebook
que la lanceuse d'alerte Frances Haugen a révélés au Wall Street Journal (2021).
On y lit que des politiciens européens avaient eux-mêmes identifié un changement
de l'algorithme de priorisation des contenus des fils d'actualité en 2018,
et que celui-ci favorisait beaucoup plus nettement les positions provocatrices et clivantes
(60 Minutes, 2021).
Une demi-décennie plus tard, 
on en paie visiblement les conséquences, 
de manière très préoccupante,
un peu partout dans le monde 
(États-Unis, Royaume-Uni, France, Allemagne, Chine, Inde, Brésil, Argentine...).

Pourtant, les algorithmes de priorisation de l'information,
qu'on appelle aussi les *intelligences artificielles* (IA) de recommandation,
restent des objets beaucoup trop rarement évoqués,
malgré des accusations de complicité de génocides et de désastres humanitaires (Amnesty 2021, 2022).
Trop souvent dans l'ombre de la hype des algorithmes génératifs,
ces IA sont pourtant beaucoup plus lucratives et invasives.
Après tout, elles sont déjà utilisées par plusieurs milliards d'humains [CITE], 
pendant plusieurs heures par jour [CITE].
Mais surtout, elles représentent le maillon essentiel pour retenir leur attention 
et pour ensuite revendre leurs temps de cerveau disponible à des annonceurs publicitaires.
Qu'on ne s'y méprenne pas.
Ce modèle d'affaire représente encore très largement l'écrasante majorité des revenus 
de la plupart des géants du numérique,
en particulier Google, Facebook, TikTok et Amazon [CITE].

À bien des égards, 
les IA de recommandation sont aussi plus complexes que les algorithmes génératifs,
notamment parce qu'elles effectuent un profilage psychologique des milliards d'utilisateur
à partir de données extrêmement invasives (Kozinsky et al. 2013),
et parce qu'elles s'appuient sur des modèles d'analyse de vidéo et de langage 
pour modérer et cataloguer les siècles de vidéos qu'elles doivent analyser chaque jour [CITE].
En fait, à ce jour, le plus grand modèle d'IA publié est une IA de recommandation [CITE].
Enfin, et surtout, 
parce que la plupart des humains accèdent désormais à l'information depuis leurs téléphones,
parce que les opérations intuitives du téléphones sont le clic, le swipe et le scroll,
et parce qu'une recommandation est attendue en réponse à ces actions,
les IA de recommandation sont très largement l'interlocuteur privilégié des internautes modernes.
Cette tendance ne semblant pas s'inverser, 
elle suggère que ces IA pourraient conserver leur rôle bien central 
dans le flux de l'information dans nos sociétés dans les décennies à venir.

Ce constat préoccupant a poussé de nombreux chercheurs et hacktivistes 
à défendre l'urgence d'un contrôle démocratique des IA en général [CITE],
et des IA de recommandation en particulier [CITE].
Cependant, au delà des nombreux défis techniques que pose un tel contrôle,
qui ont motivé une littérature scientifique fascinante sur la gouvernance algorithmique [CITE],
cette ambition soulève de nombreuses questions philosophiques [CITE].

L'objectif de cet article,
c'est de mettre en lumière trois questions philosophiques en particulier,
de montrer en quoi elles sont essentielles à la démocratie,
et d'ouvrir des pistes de réflexion.
Je n'aurai aucunement l'ambition de fournir des réponses définitives.
Au contraire, j'aspire avant tout à montrer qu'il s'agit de questions
dont il est urgent que la communauté des chercheurs en philosophie se saisissent,
avec l'ambition d'identifier des réponses consensuellement univoques
dans un futur aussi proche que possible.


## Repenser la liberté des moyens d'expression

Si tout le monde reconnaît aujourd'hui des problèmes de désinformation et de haine en ligne,
certains peuvent considérer qu'il s'agit du coût à payer,
si l'on souhaite protéger la liberté d'expression [CITE].
Cependant, cette notion qui peut paraître fondamentale 
est l'objet d'une vaste littérature [CITE],
qui en révèle toute la subtilité.
En fait, des lois encadrent déjà les limites de cette liberté,
comme l'incitation à la haine (Article R625-7 du code pénal), 
le (cyber)-harcèlement (Article 222-33-2-2 du code pénal)
et la protection des données personnelles (RGPD).

Ceci étant dit, dans l'espace informationnelle,
l'enjeu principal ne semble pas être les limites ou non
de ce que les citoyens ont le droit de déclarer.
Si des propos ignobles sont tenus sur un réseau social,
mais s'ils ne sont montrés à personne,
il n'y a pas nécessairement lieu de s'en préoccuper.
À l'inverse, si des révélations très compromettantes et très sourcées
sont publiées au sujet d'un dirigeant politique,
il y a alors un enjeu démocratique 
à ce que ces révélations soient connues des citoyens.
L'enjeu démocratique porte ainsi 
sur la *capacité de diffusion* des contenus
davantage que sur la *liberté* de les publier.

Malheureusement, une confusion récurrente entre la *liberté d'expression*
et la *liberté des moyens d'expression*,
nous semble avoir fait confondre l'idéal de la *délibération démocraitque* [CITE]
avec la nécessité d'un *marché des idées* [CITE].
Or, en pratique, le *marché des idées* s'est lui naturellement organisé
par la possession privée des *moyens d'expression*,
à l'image du rachat de médias classiques [CITE]
ou du réseau social Twitter par des milliardaires [CITE],
mais aussi du chantage d'entreprises privées du numérique comme Google et Facebook
sur des états démocratiques comme l'Australie et le Canda [CITE].
Pire encore, ce marché des idées est littéralement vendu aux plus offrants,
par des voies illégales (achats de faux comptes [CITE]) 
et légales (publicité en ligne et sponsoring d'influenceurs [CITE]).
De façon préoccupante, les inégalités de moyens d'acquisition
ont conduit à une inégalité monumentale des moyens d'expression.
Des milliardaires et des entreprises privées disposent 
d'une capacité à diffuser des messages très largement supérieure
à celles de la quasi-totalité des citoyens.

Si cette concentration des médias est une problème reconnu,
la quête d'une alternative beaucoup plus conforme aux normes démocratiques
peine encore à être un sujet de réflexion.
Il semble toutefois que la clé réside 
dans la gouvernance plus démocratique d'un *permis d'amplification massive*.
Autrement dit, il s'agirait d'impliquer les citoyens
dans le choix des sujets que les médias classiques devraient traiter,
et surtout que les IA de recommandation devraient suggérer le plus souvent.
C'est ce que proposent Hoang et Fourquet (2024),
à travers notamment la plateforme Tournesol 
qui vise à proposer un mécanisme de conception démocratique des IA de recommandation.

Par ailleurs, 
comme la vitesse du web transcende très nettement 
celle de la délibération et du vote démocratique,
tout comme celle de la justice,
il y a un enjeu urgent à ralentir les processus de viralité en ligne,
de sorte à permettre une gouvernance démocratique [CITE].
En particulier, Hoang et Fourquet (2024) proposent d'instaurer
une *présomption de non-recommandabilité massive*,
selon laquelle un contenu qui n'a pas acquis (démocratiquement)
un permis d'amplification à grande échelle
ne doit pas être recommandé massivement ---
y compris s'il est produit par une multinationale ou un milliardaire.

Ces propositions ont-elles des chances d'être des réponses consensuelles,
au moins sur le plan de la philosophie morale et politique ?
Que requièrent-elles et qu'impliquent-elles 
d'un point de vue économique, juridique et démocratique ?
Quelles solutions pragmatiques sont envisageable sur le plan technique ?
Voilà tant de questions auxquelles ce court article ne prétend pas répondre,
mais dont il semble urgent de se saisir 
pour éviter une prise de la Bastille de l'espace informationnel
par une poignée d'acteurs trop souvent trop peu alignés avec les normes démocratiques.


## Préférences instinctives et volitions réfléchies

D'une certaine manière, les IA de recommandation d'aujourd'hui
s'appuient déjà sur les préférences de nombreux citoyens
pour déterminer à quel point différents contenus doivent être recommandés.
En effet, si un contenu attise les clics, les partages et les réactions
(ce que YouTube appelle généralement « l'engagement »),
alors les IA de recommandation vont conclure 
qu'il faut davantage le recommander.

Bien entendu, cette construction est motivée avant tout 
par la maximisation de l'attention, 
et par la revente ensuite de cette attention à des annonceurs.
De plus, on peut reconnaître la manipulation des IA de recommandation
par des armées de faux comptes,
à la manière d'un bourrage des urnes,
qui rend le résultat involontairement non-représentatif des citoyens ;
on pourrait y voir davantage une faille de *sécurité* que de *fonctionnalité*.
Enfin, contrairement aux scrutins des démocraties,
la manière dont les IA de recommandation aggrègent les données des citoyens
est opaque et non-vérifiable.
Néanmoins, si ces défauts de fabrication étaient corrigés,
pourrait-on alors considérer qu'elles sont des objets démocratiques ?
Ne résultent-elles pas d'une participation citoyenne ?

Une limite évidente dans la conception des IA de recommandation
est le fait que les données des citoyens qui servent à les concevoir
n'ont pas été fournies par ces citoyens en connaissance de cause.
Plus précisément, ces citoyens n'ont généralement pas eu l'occasion 
d'avoir une délibération citoyenne informée
pour pouvoir être considéré *responsable*,
dans le sens où ces citoyens seraient en principe en mesure de *répondre*
à des questions sur les données
qu'ils ont fournies à la conception des IA de recommandation.
Plus généralement, les données des citoyens qui alimentent ces IA
peuvent être difficilement jugées être issues d'une volonté des citoyens
d'influencer le comportement des IA.

La légitimité d'une gouvernance démocratique semble ainsi dépendre de manière essentielle
de l'état d'esprit dans lequel les citoyens fournissent les données
qui seront utilisées pour déterminer les objets démocratiques.
À cet égard, [CITE] soulignent cette nécessité de *choix délibéré*,
voire de choix *informé* et bien *mûri*,
en parlant de *volition réfléchie*,
par opposition aux *préférences instinctives* 
qui guident tant des activités des citoyens en ligne en pratique.
Une gouvernance démocratique ne serait ainsi satisfaisante
que si elle est une gouvernance des *volitions*,
plutôt qu'une gouvernance des *préférences*.
La plateforme Tournesol a d'ailleurs révélé des écarts de jugements
enrte les préférences fournies rapidement 
et celles qui semblent résulter de volitions plus réfléchies [CITE],
suggérant toute l'importance de cette distinction.

Si l'on accepte la prévalence des volitions sur les préférences,
il reste à déterminer les dispositifs pratiques
qui permettront de valoriser ces volitions aux dépens des préférences,
voire qui permettront des distinguer les volitions des préférences.
Hors ligne, l'article L49 du code électoral, par exemple,
interdit toute campagne électorale le jour d'une élection.
Voilà qui permet d'encourager une journée de réflexion,
et limite le risque de décisions de vote plus instinctives.
De même, en ligne, il serait peut-être adéquat de pousser
les citoyens à prendre du recul et un temps de réflexion
avant qu'ils ne fournissent les données qui seront utilisées 
pour concevoir et gouverner les IA.

L'une des initiatives les plus intéressantes à cet égard
est l'introduction des *Community Notes* sur Twitter [CITE],
qui visaient à contextualiser les messages publiés sur la plateforme,
pour permettre aux utilisateurs de prendre du recul
avant d'éventuellement les "liker" et les partager.
Même si ces notes sont par ailleurs critiquables,
notamment à cause de failles de sécurité [CITE],
elles suggèrent une voie prometteuse vers la gouvernance des volitions.
Mais comment pourrait-on aller plus loin ?
Comment favoriser, puis identifier, les volitions dans le cyber espace ?
Quelles sont les conditions sous lesquelles 
un jugement peut être consensuellement jugé plus délibéré et informé qu'un autre ?


## Prioriser le consensus radical aux impasses clivantes

De nos jours, on peut avoir l'impression que les démocraties *divisent*,
à l'image du débat froid et glaçant entre les candidats à la présidence des États-Unis
Donald Trump et Joe Biden en juin 2024.
Cependant, les images du débat entre Mitt Romney et Barack Obama en octobre 2012
suggèrent que ce n'est pas une fatalité.
Mais alors, que s'est-il passé ?
Comment tant de distances, voire tant de haines, ont pu émergé
entre des représentants politiques,
ainsi qu'entre des clans de l'électorat qu'ils représentent ?

Selon [CITE], 
une partie de la réponse réside dans la mise en avant systématique des sujets clivants,
qui suscitent naturellement plus d'engagements,
et donc plus de revenus pour les réseaux sociaux [CITE].
Malheureusement, des études [CITE] montrent que ces sujets clivants clivent ;
en particulier, l'exposition au point de vue opposé a tendance à exacerber les tensions,
plutôt qu'à rapprocher les points de vues.
Mais surtout, ces sujets clivants sont souvent des impasses démocratiques,
puisqu'aucune solution ne semble alors en mesure d'être démocratiquement satisfaisante.
Mais alors, plutôt que de gaspiller énormément de temps et d'énergie,
et de sacrifier de la cohésion sociale,
à focaliser notre attention sur des impasses,
ne serait-il pas plus judicieux d'identifier les mesures urgentes à mettre en place,
et que la population juge désirables de manière presque consensuelle ?

Ces consensus, qu'on pourrait qualifier de *radicaux* dans la mesure 
où ils impliquent des interventions,
peuvent paraître être une chimère à certains.
Mais si c'est le cas, c'est sans doute précisément 
à cause de l'attention démesurée donnée aux conflits dans nos démocraties.
Pourtant, même sur un sujet aussi clivant que les violences policières à l'été 2023 en France,
une délibération menée en ligne via la plateforme *Pol.is* [CITE]
a identifié de tels consensus radicaux.
Certes, il y a bien deux clans qui s'opposent ;
mais les deux clans s'accordent en fait en grande majorité 
sur l'urgence d'investir davantage dans la formation des policiers d'une part,
et dans la police de proximité d'autre part [CITE].
Malheureusement, ces consensus radicaux ont été noyées dans l'océan de haine
qu'alimentent les IA de recommandation aujourd'hui,
si bien que les volontés les plus démocratiques sont aujourd'hui inconnues,
et mises au placard.
On dit parfois d'eux qu'ils sont des *mute news* [CITE],
c'est-à-dire des informations rendues silencieuses 
par une compétition plus médiatisée et amplifiée par les IA de recommandation.

De manière plus fondamentale,
l'enjeu philosophique est de déterminer la priorisation relative
entre des sujets où une faible majorité a un avis extrêmement prononcé,
et des sujets où une écrasante majorité a une même opinion,
qui implique des changements de société radicaux.
Comment en particulier fonder la légitimité de mécanismes pratiques
qui favoriseraient les seconds aux premiers ?
Quelles solutions pratiques peuvent-être envisagées
pour que la démocratie soit gouverner par le consensus des volitions,
plutôt que par la majorité des préférences ?
Et en particulier, peut-on identifier des consensus radicaux,
au moins au sein de la communauté des philosphes,
sur l'identification et la valorisation des consensus radicaux ?


## Conclusion

Comme on l'a souligné en introduction,
il y a urgence aujourd'hui à rendre la gouvernance de notre espace informationnel,
y compris la partie numérisée de cet espace,
beaucoup plus démocratique.
Année après année, de nombreuses démocraties à travers le monde reculent,
déstabilisées par un espace informationnel dévasté par des armées de faux comptes,
et par des industriels qui priorisent leurs profits à la protection des démocraties.
Cependant, au delà des défis socio-techniques évidents que cela pose,
il y a de nombreuses questions philosophiques fondamentales,
qui manquent aujourd'hui cruellement d'attention et de réponses,
et qu'il nous faut urgemment éclaircir pour asseoir l'intégrité et la légitimité
d'une solution de gouvernance démocratique du cyber espace.

Dans cet article, j'ai cherché à clarifier trois questions en particulier,
à savoir la gouvernance du permis d'amplification massive,
la distinction entre préférences instinctives et volitions réfléchies
et la priorisation des consensus radicaux aux dépens des impasses clivantes,
sans toutefois viser à fournir des conclusions péremptoires.
J'espère en particulier motiver plus de recherches,
pour identifier de potentielles réponses consensuellement univoques.
Par ailleurs, j'ai pour objectif de partager ma curiosité pour ces considérations,
qui me semblent être d'une grande richesse philosophique insuffisamment explorée.


## Références

60 Minutes 2021
Amnesty 2021 2022
Aral 2020
Chavalarias 2022
Global State of Democracy Initative 2024
Tufekci 2017
V-Dem Institute 2024
Wall Street Journal 2021


## Biographie

Polytechnicien, docteur en mathématiques, Lê Nguyên Hoang a été chercheur au MIT et à l’EPFL,
où il s'intéressait à la sécurité des systèmes d'intelligence artificielle 
et à la gouvernance démocratique des algorithmes.
PDG cofondateur de Calicarpa, 
créateur de la chaîne YouTube Science4All 
et président de l’association Tournesol, 
il est coauteur de nombreux ouvrages de vulgarisation scientifique, 
dont "La dictature des algorithmes", 
co-écrit avec Jean-Lou Fourquet aux éditions Tallandier en 2024.

