# Trois questions philosophiques sur la démocratie numérique

« Le niveau de démocratie dont jouit le citoyen moyen dans le monde en 2023 
est retombé à son niveau de 1985 », 
peut-on lire dans le rapport 2024 du V-Dem Institute (Nord et al. 2024).
« Les déclins de la démocratie continuent d'être plus nombreux que les progrès »,
ajoute l'analyse 2024 du Global State of Democracy Initative,
un institut intergouvernemental associé à l'Organisation des Nations Unies.
Depuis une décennie en particulier,
les démocraties sont de plus en plus confrontées à des dérives autoritaires et populistes,
alimentées par la désinformation et la haine.

S'ils ne sont pas les seuls responsables,
les réseaux sociaux ont été souvent identifiés
comme l'une des sources majeures de l'amplification de ces dérives 
(Tufekci 2017, Aral 2020, Chavalarias 2022).
L'élément à charge le plus compromettant nous vient peut-être des *Facebook Files*,
des documents internes à l'entreprise Facebook
que la lanceuse d'alerte Frances Haugen a révélés au Wall Street Journal (2021).
On y lit que des politiciens européens avaient eux-mêmes identifié un changement
de l'algorithme de priorisation des contenus des fils d'actualité en 2018,
et que celui-ci favorisait beaucoup plus nettement les positions provocatrices et clivantes
(Pelley 2021).
Une demi-décennie plus tard, 
on en paie visiblement les conséquences, 
de manière très préoccupante,
un peu partout dans le monde 
(États-Unis, Royaume-Uni, France, Allemagne, Chine, Inde, Brésil, Argentine...).

Pourtant, les algorithmes de priorisation de l'information,
qu'on appelle aussi les *intelligences artificielles* (IA) de recommandation,
restent des objets beaucoup trop rarement évoqués,
malgré des accusations de complicité de génocides et de désastres humanitaires 
(Amnesty International 2022, 2023).
Trop souvent dans l'ombre de la hype des algorithmes génératifs,
ces IA sont pourtant beaucoup plus lucratives et invasives.
Après tout, elles sont déjà utilisées par plusieurs milliards d'humains, 
pendant plusieurs heures par jour (Ortiz-Ospina 2019).
Mais surtout, elles représentent le maillon essentiel pour retenir leur attention 
et pour ensuite revendre leurs temps de cerveau disponible à des annonceurs publicitaires.
Qu'on ne s'y méprenne pas.
Ce modèle d'affaire représente encore très largement l'écrasante majorité des revenus 
de la plupart des géants du numérique,
en particulier Google, Facebook, TikTok et Amazon (Elias 2024, Kim 2024).

À bien des égards, 
les IA de recommandation sont aussi plus complexes que les algorithmes génératifs,
notamment parce qu'elles effectuent un profilage psychologique de milliards d'utilisateurs
à partir de données extrêmement intrusives (Kosinsky et al. 2013),
et parce qu'elles s'appuient sur les meilleurs modèles d'analyse de vidéo et de langage 
pour modérer et cataloguer les siècles de vidéos 
qu'elles doivent analyser chaque jour (YouTube for Press 2024).
En fait, à ce jour, 
le plus grand modèle d'IA publié est une IA de recommandation (Lian et al. 2022),
avec ses centaines de millions de milliards de paramètres.
Enfin, et surtout, 
parce que la plupart des humains accèdent désormais à l'information depuis leurs téléphones,
parce que les opérations intuitives du téléphones sont le clic, le swipe et le scroll,
et parce qu'une recommandation est attendue en réponse à ces actions,
les IA de recommandation sont très largement l'interlocuteur privilégié des internautes modernes.
Cette tendance ne semblant pas s'inverser, 
elle suggère que ces IA pourraient conserver leur rôle central 
dans le flux de l'information dans nos sociétés dans les décennies à venir.

Ce constat préoccupant a poussé de nombreux chercheurs et hacktivistes 
à défendre l'urgence d'un contrôle démocratique des IA en général (Hoang 2023),
et des IA de recommandation en particulier (Gibert et al. 2024, Hoang et Fourquet 2024).
Cependant, au delà des nombreux défis techniques que pose un tel contrôle,
qui ont motivé une littérature scientifique fascinante 
sur la gouvernance algorithmique (Noothigattu et al. 2018, Lee et al. 2019, Freedman et al. 2020),
cette ambition soulève de nombreuses questions philosophiques.

L'objectif de cet article,
c'est de mettre en lumière trois questions philosophiques en particulier,
de montrer en quoi elles sont essentielles à la démocratie,
et d'ouvrir des pistes de réflexion.
Je n'aurai aucunement l'ambition de fournir des réponses définitives.
Au contraire, j'aspire avant tout à montrer qu'il s'agit de questions
dont il est urgent que la communauté des chercheurs en philosophie se saisissent,
avec l'ambition d'identifier des réponses consensuellement univoques
dans un futur aussi proche que possible.


## Repenser la liberté des moyens d'expression

Si tout le monde reconnaît aujourd'hui des problèmes de désinformation et de haine en ligne,
certains peuvent considérer qu'il s'agit du coût à payer,
si l'on souhaite protéger la liberté d'expression (Cohen-Almagor 2015).
Cependant, cette notion qui peut paraître fondamentale 
est l'objet d'une vaste littérature 
(Ammori 2012, Girard 2016, Kloninck 2018, Kaye 2019, Marciel 2023),
qui en révèle toute la subtilité.
En fait, des lois encadrent déjà les limites de cette liberté,
comme l'incitation à la haine (Article R625-7 du code pénal), 
le (cyber)-harcèlement (Article 222-33-2-2 du code pénal)
et la protection des données personnelles (RGPD).

Ceci étant dit, dans l'espace informationnel,
l'enjeu principal ne semble pas être les limites ou non
de ce que les citoyens ont le droit de déclarer.
Si des propos ignobles sont tenus sur un réseau social,
mais s'ils ne sont montrés à personne,
il n'y a pas nécessairement lieu de s'en préoccuper.
À l'inverse, si des révélations très compromettantes et très sourcées
sont publiées au sujet d'un dirigeant politique,
il y a alors un enjeu démocratique 
à ce que ces révélations soient connues des citoyens.
L'enjeu démocratique porte ainsi 
sur la *capacité de diffusion* des contenus
davantage que sur la *liberté* de les publier.

Malheureusement, une confusion récurrente entre la *liberté d'expression*
et la *liberté des moyens d'expression*,
nous semble avoir fait confondre l'idéal de la *délibération démocratique* (Landermore 2017)
avec la nécessité d'un *marché des idées* (Ingber 1984).
Or, en pratique, le *marché des idées* s'est lui naturellement organisé
par la possession privée des *moyens d'expression*,
à l'image du rachat de médias traditionnels
ou du réseau social Twitter par des milliardaires (Cagé 2015, Benton et al. 2022),
et comme l'illustre aussi le chantage d'entreprises privées du numérique comme Google et Facebook
sur des états démocratiques comme l'Australie et le Canada (Morris-Grant 2024).
Pire encore, ce marché des idées est littéralement vendu aux plus offrants,
par des voies illégales (achats de faux comptes, Huang et Liu 2024) 
et légales (publicité en ligne et sponsoring d'influenceurs, Leung et al. 2022).
De façon préoccupante, les inégalités de moyens d'acquisition
ont conduit à une inégalité monumentale des moyens d'expression.
Des milliardaires et des entreprises privées disposent 
d'une capacité à diffuser des messages très largement supérieure
à celles de la quasi-totalité des citoyens.

Si cette concentration des médias est un problème reconnu,
la quête d'une alternative beaucoup plus conforme aux normes démocratiques
peine encore à être un sujet de réflexion.
Il semble toutefois que la clé réside 
dans la gouvernance plus démocratique d'un *permis d'amplification massive*.
Autrement dit, il s'agirait d'impliquer les citoyens
dans le choix des sujets que les médias classiques devraient traiter,
et surtout que les IA de recommandation devraient suggérer le plus souvent.
C'est ce que proposent Hoang et Fourquet (2024),
à travers notamment la plateforme Tournesol 
qui développe un mécanisme de conception démocratique des IA de recommandation.

Par ailleurs, 
comme la vitesse du web transcende très nettement 
celle de la délibération et du vote démocratique,
tout comme celle de la justice,
il y a un enjeu urgent à ralentir les processus de viralité en ligne,
de sorte à permettre une gouvernance démocratique (Boullier 2020).
En particulier, Hoang et Fourquet (2024) proposent d'instaurer
une *présomption de non-recommandabilité massive*,
selon laquelle un contenu qui n'a pas acquis (démocratiquement)
un permis d'amplification à grande échelle
ne doit pas être recommandé massivement --
y compris s'il est produit par une multinationale ou un milliardaire.

Ces propositions ont-elles des chances d'être des réponses consensuelles,
au moins sur le plan de la philosophie morale et politique ?
Que requièrent-elles et qu'impliquent-elles 
d'un point de vue économique, juridique et démocratique ?
Quelles solutions pragmatiques sont envisageable sur le plan technique ?
Voilà tant de questions auxquelles ce court article ne prétend pas répondre,
mais dont il semble urgent de se saisir 
pour éviter une prise de la Bastille informationnelle
par une poignée d'acteurs trop souvent trop peu alignés avec les normes démocratiques.


## Préférences instinctives et volitions réfléchies

D'une certaine manière, les IA de recommandation d'aujourd'hui
s'appuient déjà sur les préférences de nombreux citoyens
pour déterminer à quel point différents contenus doivent être recommandés.
En effet, si un contenu attise les clics, les partages et les réactions
(ce que YouTube appelle généralement « l'engagement »),
alors les IA de recommandation vont conclure 
qu'il faut davantage le recommander.

Bien entendu, cette construction est motivée avant tout 
par la maximisation de l'attention, 
et par la revente ensuite de cette attention à des annonceurs.
De plus, on peut reconnaître la manipulation des IA de recommandation
par des armées de faux comptes,
à la manière d'un bourrage des urnes,
qui rend le résultat involontairement non-représentatif des citoyens ;
on pourrait y voir davantage une faille de *sécurité* que de *fonctionnalité*.
Enfin, contrairement aux scrutins des démocraties,
la manière dont les IA de recommandation aggrègent les données des citoyens
est opaque et non-vérifiable.
Néanmoins, si ces défauts de fabrication étaient corrigés,
pourrait-on alors considérer qu'elles sont des objets démocratiques ?
Ne résultent-elles pas d'une participation citoyenne ?

Une limite évidente dans la conception des IA de recommandation
est le fait que les données des citoyens qui servent à les concevoir
n'ont pas été fournies par ces citoyens en connaissance de cause.
Plus précisément, ces citoyens n'ont généralement pas eu l'occasion 
d'avoir une délibération citoyenne informée
pour pouvoir être considéré *responsable*,
dans le sens où ces citoyens seraient en principe en mesure de *répondre*
à des questions sur les données
qu'ils ont fournies à la conception des IA de recommandation.

La légitimité d'une gouvernance démocratique semble ainsi dépendre de manière essentielle
de l'état d'esprit dans lequel les citoyens fournissent les données
qui seront utilisées pour déterminer les objets démocratiques.
À cet égard, Hoang (2019), Søvik (2022) et Lechiakh et Maurer (2023) 
soulignent cette nécessité de *choix délibéré*,
voire de choix *informé* et bien *mûri*,
en parlant de *volition réfléchie*,
par opposition aux *préférences instinctives* 
qui guident davantage les activités des citoyens en ligne en pratique.
Une gouvernance démocratique ne serait ainsi satisfaisante
que si elle est une gouvernance des *volitions*,
plutôt qu'une gouvernance des *préférences*.
La plateforme Tournesol a d'ailleurs révélé des écarts de jugements
entre les préférences fournies rapidement 
et celles qui semblent résulter de volitions plus réfléchies (Hoang et al. 2024),
suggérant toute l'importance de cette distinction.

Si l'on accepte la prévalence des volitions sur les préférences,
il reste à déterminer les dispositifs pratiques
qui permettront de valoriser ces volitions aux dépens des préférences,
voire qui permettront de distinguer les volitions des préférences.
Hors ligne, l'article L49 du code électoral, par exemple,
interdit toute campagne électorale la veille et le jour d'une élection.
Voilà qui permet d'encourager au moins une journée de réflexion,
et limite le risque de décisions de vote plus instinctives.
Plus récemment, 
la Convention Citoyenne sur le Climat a donné 
à un échantillon de 150 citoyens tirés au hasard
un an de formation, de réflexion et de délibérations,
pour aboutir à des propositions issues de volitions informées (Pech 2021).

De même, en ligne, il serait peut-être adéquat de pousser
les citoyens à prendre du recul et un temps de réflexion
avant qu'ils ne fournissent les données qui seront utilisées 
pour concevoir et gouverner les IA.
L'une des initiatives les plus intéressantes à cet égard
est l'introduction des *Community Notes* sur Twitter 
(Wirtschafter et Majumder 2023, Pilarski et al. 2024),
qui visent à contextualiser les messages publiés sur la plateforme,
pour permettre aux utilisateurs de prendre du recul
avant d'éventuellement les "liker" et les partager.
Même si ces notes sont par ailleurs critiquables,
notamment à cause de failles de sécurité (Elliot et Gilbert 2023),
elles suggèrent une voie prometteuse vers la gouvernance des volitions.
Mais comment pourrait-on aller plus loin ?
Comment favoriser, puis identifier, les volitions dans le cyber espace ?
Quelles sont les conditions sous lesquelles 
un jugement peut être consensuellement jugé plus délibéré et informé qu'un autre ?


## Prioriser le consensus radical aux impasses clivantes

De nos jours, on peut avoir l'impression que les démocraties *divisent*,
à l'image du débat froid et glaçant entre les candidats à la présidence des États-Unis
Donald Trump et Joe Biden en juin 2024.
Cependant, les images du débat entre Mitt Romney et Barack Obama en octobre 2012
suggèrent que ce n'est pas une fatalité.
Mais alors, que s'est-il passé ?
Comment tant de distances, voire tant de haines, ont pu émergé
entre des représentants politiques,
ainsi qu'entre les clans de l'électorat qu'ils représentent ?

Selon Törnberg (2022), 
une partie de la réponse réside dans la mise en avant systématique des sujets clivants,
qui suscitent naturellement plus d'engagements,
et donc plus de revenus pour les réseaux sociaux (Berger et Milkman 2012).
Malheureusement, des études (Balietti et al. 2021, Axelrod et al. 2021)
montrent que ces sujets clivants clivent ;
en particulier, l'exposition au point de vue opposé a tendance à exacerber les tensions,
plutôt qu'à rapprocher les points de vues.
Mais surtout, ces sujets clivants sont souvent des impasses démocratiques,
puisqu'aucune solution ne semble alors en mesure d'être démocratiquement satisfaisante.
Mais alors, plutôt que de gaspiller énormément de temps et d'énergie,
et de sacrifier de la cohésion sociale,
à focaliser notre attention sur des impasses,
ne serait-il pas plus judicieux d'identifier les mesures urgentes à mettre en place,
et que la population juge désirables de manière presque consensuelle ?

Ces consensus, qu'on pourrait qualifier de *radicaux* dans la mesure 
où ils impliquent des interventions,
peuvent paraître être une chimère.
Mais si c'est le cas, c'est sans doute précisément 
à cause de l'attention démesurée donnée aux conflits dans nos démocraties.
Pourtant, même sur un sujet aussi clivant que les violences policières à l'été 2023 en France,
une délibération menée en ligne via la plateforme *Pol.is* (Small et al., 2021)
a identifié de tels consensus radicaux.
Certes, il y a bien deux clans qui s'opposent ;
mais les deux clans s'accordent en fait en grande majorité 
sur l'urgence d'investir davantage dans la formation des policiers d'une part,
et dans la police de proximité d'autre part (Pech 2023).
Malheureusement, ces consensus radicaux ont été noyées dans l'océan de haine
qu'alimentent les IA de recommandation d'aujourd'hui,
si bien que les volontés les plus démocratiques sont aujourd'hui méconnues,
et mises au placard.
On dit parfois qu'elles sont des *mute news* (Hoang 2020),
c'est-à-dire des informations rendues silencieuses 
par une compétition plus médiatisée et amplifiée par les IA de recommandation.

De manière plus fondamentale,
l'enjeu philosophique est de déterminer la priorisation relative
entre des sujets où une faible majorité a un avis extrêmement prononcé,
et des sujets où une écrasante majorité a une même opinion,
qui implique des changements de société radicaux.
Comment en particulier fonder la légitimité de mécanismes
qui favoriseraient les seconds aux premiers ?
Quelles solutions pratiques peuvent-être envisagées
pour que la démocratie soit gouvernée par le consensus des volitions,
plutôt que par la majorité des préférences ?
Et en particulier, peut-on identifier des consensus radicaux,
au moins au sein de la communauté des philosphes,
sur l'identification et la valorisation des consensus radicaux ?


## Conclusion

Comme on l'a souligné en introduction,
il y a urgence aujourd'hui à rendre la gouvernance de notre espace informationnel,
y compris la partie numérisée de cet espace,
beaucoup plus démocratique.
Année après année, de nombreuses démocraties à travers le monde reculent,
déstabilisées par un espace informationnel dévasté par des armées de faux comptes,
et par des industriels qui priorisent leurs profits à la protection des démocraties.
Cependant, au delà des défis socio-techniques évidents que cela pose,
il y a de nombreuses questions philosophiques fondamentales,
qui manquent aujourd'hui cruellement d'attention et de réponses,
et qu'il nous faut urgemment éclaircir pour asseoir l'intégrité et la légitimité
d'une solution de gouvernance démocratique du cyber espace.

Dans cet article, j'ai cherché à clarifier trois questions en particulier,
à savoir la gouvernance du permis d'amplification massive,
la valorisation des volitions réfléchies
et la priorisation des consensus radicaux,
sans toutefois viser à fournir des conclusions péremptoires.
J'espère en particulier motiver plus de recherches,
pour identifier de potentielles réponses consensuellement univoques
à des enjeux civilisationnels brûlants.
Par ailleurs, j'ai pour objectif de partager ma curiosité pour ces considérations,
qui me semblent être d'une formidable richesse philosophique insuffisamment explorée.


## Références

Ammori N (2012). First Amendment Architecture. Wisconsin Law Review.

Amnesty International (2022). Myanmar: Facebook’s systems promoted violence against Rohingya; Meta owes reparations.

Amnesty International (2023). Ethiopia: Meta’s failures contributed to abuses against Tigrayan community during conflict in northern Ethiopia.

Aral S (2020). The Hype Machine: How Social Media Disrupts Our Elections, Our Economy, and Our Health--and How We Must Adapt. Penguin 2020.

Axelrod R, Daymude JJ, Forrest S (2021). Preventing extreme polarization of political attitudes. PNAS.

Balietti S, Getoor L, Goldstein DG, Watts DJ (2021). Reducing opinion polarization: Effects of exposure to similar people with differing political views. PNAS.

Benton B, Choi JA, Luo Y, Green K (2022). Hate speech spikes on Twitter after Elon Musk acquires the platform. School of Communication and Media, Montclair State University.

Berger JA, Milkman KL (2012). What Makes Online Content Viral? Journal of Marketing Research.

Small C, Bjorkegren M, Erkkilä T, Shaw L, Megill C (2021). Polis: Scaling deliberation by mapping high dimensional opinion spaces. Recerca: revista de pensament i anàlisi.

Boullier (2020). Comment sortir de l’emprise des réseaux sociaux, Paris, Le Passeur.

Cagé J (2015). Sauver les médias. Capitalisme, financement participatif et démocratie: Capitalisme, financement participatif et démocratie. Média Diffusion.

Chavalarias D (2022). Toxic Data : Comment les réseaux manipulent nos opinions. Flammarion.

Cohen-Almagor R (2015). Confronting the Internet's Dark Side: Moral and Social Responsibility on the Free Highway. Cambridge University Press.

Elias J (2024). Alphabet meets earnings expectations but misses on YouTube ad revenue. CNBC.

Elliott V, Gilbert D (2023). Elon Musk’s Main Tool for Fighting Disinformation on X Is Making the Problem Worse, Insiders Claim. Wired.

Freedman R, Borg JS, Sinnott-Armstrong W, Dickerson JP, Conitzer V (2020). Adapting a kidney exchange algorithm to align with human values. Artificial Intelligence.

Gibert M, Hoang LN, Lambrecht M (2024). Should YouTube make recommendations for the climate?. Ethics and Information Technology.

Girard C (2016). La liberté d'expression : état des questions. Raisons Politiques.

Hagey K and Horwitz J (2021). Facebook Tried to Make Its Platform a Healthier Place. It Got Angrier Instead. Wall Street Journal.

Hoang LN (2019). Towards Robust End-to-End Alignment. SafeAI@AAAI.

Hoang LN (2020). Science communication desperately needs more aligned recommendation algorithms. Frontiers in Communication.

Hoang LN (2023). Les IA échappent au contrôle démocratique. SwissInfo.

Hoang LN, Fourquet JL (2024). La Dictature des Algorithmes : Une transition numérique démocratique est possible. Tallandier.

Hoang LN, Beylerian R, Fageot J, Faucon L, Jungo A, Matissart A, Nogues N, Villemaud O (2024). The Tournesol dataset: Which videos should be more largely recommended? Preprint.

Huang Z, Liu D (2024). Economics of social media fake accounts. Management Science.

Ingber S (1984). The marketplace of ideas: a legitimizing myth. Duke Law Journal.

Kaye D (2019). Speech Police. The global struggle to govern the internet. Columbia Global Reports.

Kloninck K (2018). The New governors: The people, rules, and processes governing Online Speech. Harvard Law Review.

Kim HY (2024). What’s wrong with relying on targeted advertising? Targeting the business model of social media platforms. Critical Review of International Social and Political Philosophy.

Kosinsky M, Stillwell D, Graepel T (2013). Private traits and attributes are predictable from digital records of human behavior. PNAS.

Landermore H (2017). Deliberative Democracy as Open, Not (Just) Representative Democracy. Dædalus.

Lechiakh M, Maurer A (2023). Volition Learning: What Would You Prefer to Prefer? CHI.

Leung FF, Gu FF, Palmatier RW (2022). Online influencer marketing. Journal of the Academy of Marketing Science.

Lian X, Yuan B, Zhu X, Wang Y, He Y, Wu H, ... Liu J (2022). Persia: An open, hybrid system scaling deep learning-based recommenders up to 100 trillion parameters. ACM SIGKDD.

Marciel R (2023). On citizens' right to information: Justification and analysis of the Democratic Right to be well informed. Journal of Political Philosophy.

Noothigattu R, Gaikwad S, Awad E, Dsouza S, Rahwan I, Ravikumar P, Procaccia A (2018). A voting-based system for ethical decision making. AAAI.

Lee MK, Kusbit D, Kahng A, Kim JT, Yuan X, Chan A, See D, Noothigattu R, Lee S, Psomas A, Procaccia A (2019). WebuildAI: Participatory framework for algorithmic governance. ACM HCI.

Morris-Grant B (2024). Meta blocked news from Facebook and Instagram in Canada — could they do the same in Australia? ABC News.

Nord M, Lundstedt M, Angiolillo F, Borella C, Gastaldi L, Good God A, Natsika N, Lindberg SI (2024). Democracy Winning and Losing at the Ballot: Democracy Report 2024. V-Dem Institute 2024.

Ortiz-Ospina (2019). The rise of social media. Our World in Data.

Pech, T. (2021). Le Parlement des citoyens: La convention citoyenne pour le climat. Seuil.

Pech T (2023). Pol.is sur la Police, bilan d’une expérimentation. La Grande Conversation.

Pelley S (2021). Whistleblower: Facebook is misleading the public on progress against hate speech, violence, misinformation. CBS News.

Pilarski M, Solovev KO, Pröllochs N (2024). Community Notes vs. Snoping: How the Crowd Selects Fact-Checking Targets on Social Media. AAAI on Web and Social Media.

Søvik AO (2022). What overarching ethical principle should a superintelligent AI follow? AI & SOCIETY.

The Global State of Democracy 2024: Strengthening the Legitimacy of Elections in a Time of Radical Uncertainty. International IDEA.

Törnberg P (2022). How digital media drive affective polarization through partisan sorting. PNAS.

Tufekci Z (2017). Twitter and Tear Gas: The Power and Fragility of Networked Protest. Yale University Press.

YouTube for Press (2024). blog.youtube/press.

Wirtschafter V, Majumder S (2023). Future Challenges for Online, Crowdsourced Content Moderation: Evidence from Twitter’s Community Notes. Journal of Online Trust and Safety.


## Biographie

Polytechnicien, docteur en mathématiques, Lê Nguyên Hoang a été chercheur au MIT et à l’EPFL,
où il s'intéressait à la sécurité des systèmes d'intelligence artificielle 
et à la gouvernance démocratique des algorithmes.
PDG cofondateur de Calicarpa, 
créateur de la chaîne YouTube Science4All 
et président de l’association Tournesol, 
il est coauteur de nombreux ouvrages de vulgarisation scientifique, 
dont "La dictature des algorithmes", 
co-écrit avec Jean-Lou Fourquet aux éditions Tallandier en 2024.

