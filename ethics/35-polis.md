# Le danger du débat unidimensionnel

Quand on parle de crise informationnelle, 
il est tentant de sauter à pied joint sur le problème des fake news,
ces fausses informations qui se propagent si vite à travers le web.
Cependant, réduire la crise informationnelle à qui détient la vérité,
voire, pire encore, à la déconstruction des fausses informations,
cela peut être l'objectif recherché par ceux qui veulent provoquer cette crise informationnelle.

Aujourd'hui, je vous propose d'analyser
l'une des attaques informationnelles les plus importantes de l'histoire,
et de montrer le danger qu'il y a à se perdre dans le debunking de l'information,
souvent au prix de la paralysie parlementaire,
d'une haine au sein de la société qui peut déraper,
et surtout, des #MuteNews, ces informations si essentielles pour nos démocraties,
mais qui se retrouvent trop souvent noyées dans une cacophonie incontrôlée.

Mais surtout, on va voir comment nos sociétés peuvent se protéger
contre de telles ingérences de notre espace informationnel,
en exploitant la multidimensionalité de l'espace des débats,
et en cherchant à projeter le débat dans les directions les plus fructueuses,
aussi bien pour l'union démocratique,
que pour l'efficacité des prises de décision collectives.

Alors, ça peut paraître très fumeux ce que je viens de dire ;
mais on va voir que la multidimensionalité de l'espace des débats,
ça correspond vraiment à un espace mathématique
que je prends personnellement énormément de plaisir à explorer et à comprendre.
Et je vais même vous proposer un modèle mathématique inédit qui formalise cela,
avec des conjectures pour les plus motivés parmi vous.

Mais surtout, chercher les projections les plus démocratiquement fructueuses,
c'est vraiment un aspect au coeur de ma recherche,
de la plateforme Polis et du projet Tournesol,
dont on va voir des applications stupéfiantes,
notamment par exemple dans le cas de la résolution des violences policières en France.

Et en particulier, j'aurai le grand plaisir de vous montrer le cas d'une consultation
que Jean-Lou Fourquet, alias Après La Bière, et moi avons menée,
sur les meilleures manières de communiquer au sujet de la sécurité des IA,
avec quelques enseignements très concrets.


## Diviser pour régner

Pour bien comprendre le danger de s’attarder sur les fausses informations,
je vous invite à écouter ce court extrait d'une vidéo de Smarter Every Day :

> 9:15 One of the things that Facebook discovered is that these bad guys
> were purchasing advertisements and putting them on the Internet
> to try to divide and anger specific groups of people, for instance Christians [...]
> I want to speak to this one, because I'm a Christian [...]
> Every Christian I know would look at this and not only roll their eyes.
> But this kind of thing breaks our hearts [...]
> The real thing that hurts here is I'm afraid my non-Christian friends will see this,
> and think that that represents people that share my faith.
> Lowbrow, combative, easily manipulated.
> You see the play here?
> It doesn't have to be the legitimate viewpoint of anyone for this to be effective.
> It only has to vaguely resemble some semblance of truth
> and that will plant the seeds.
> And then our fears, biases and insecurities will take over from there [...]
> And they did it with thousands of different ads across tons of divisive topics.
> Honestly, how many good interactions would you have to have
> in order to offset the negative impressions caused in your minds
> by interacting with one of these memes?  
> https://tournesol.app/entities/yt:FY_NtO7SIrY

Vous voyez ce qu'il se passe ?
Quand on voit un contenu révoltant,
notamment sachant à quel point il est faux,
notre premier réflexe, ça va être de vouloir le débunker,
et de lui consacrer énormément d'attention.
Sauf que ça, c'est exactement le but recherché par les attaques informationnelles.

Oui, elles s'appuient souvent sur de fausses informations,
mais leur objectif premier n'est en général pas de diffuser des fausses informations.
Elles vont davantage chercher à diviser nos sociétés,
en les poussant à donner pleine attention aux sujets qui divisent,
et même en exacerbant les tensions en offrant des hommes de paille du clan opposé
à chacun des clans politiques,
de sorte à pousser les populations à ressentir avant tout de la haine
envers une énorme fraction de leurs concitoyens.

C'est typiquement la stratégie adoptée par le vice-président des États-Unis JD Vance
dans son intervention à la Conférence de Munich sur la Sécurité,
pour affaiblir le continent européen dans les négociations avec Trump.

> La menace qui m'inquiète le plus vis-à-vis de l'Europe,
> ce n'est pas la Russie, ce n'est pas la Chine,
> ce n'est aucun acteur extérieur.
> Ce qui m'inquiète, c'est la menace de l'intérieur [...]
> Je regarde à Bruxelles, où des commissaires européens ont dit
> qu'ils avaient l'intention d'éteindre les réseaux sociaux
> lors de mouvements sociaux au moment où ils voient ce qu'ils appellent,
> je cite, des "contenus de haine".  
> https://tournesol.app/entities/yt:pCOsgfINdKg 

En fait, comme cet extrait le montre,
ces attaques informationnelles n'ont pas besoin d'exploiter
des fausses affirmations pour atteindre leur objectif.
Cependant, notamment lorsqu'elles s'attaquent à des sociétés ou des communautés
qui sont particulièrement promptes à débunker des fausses affirmations,
diffuser des affirmations fausses peut en fait surtout aider à être plus viral,
à l'instar de l'internaute mis en scène dans ce dessin d'xkcd.  
https://xkcd.com/386/ 

Oui, j'avoue, j'ai moi aussi déjà été ce mec absorbé dans un puits attentionnel,
juste parce que quelqu'un a dit une chose fausse sur Internet...
En fait, c'est parce que je n'ai pas voulu donner plus d'attention que cela à JD Vance,
j'ai choisi un extrait sans mensonges,
alors que si vous écoutez son discours,
ce n'est pas difficile d'y trouver plein de fausses informations,
et c'est si tentant de passer son temps à les déconstruire.

Mais ce serait tomber à pied joint dans le piège tendu par JD Vance,
tout comme la Russie avait tendu un piège à la démocratie étatsunienne en 2016.
Dans une étude publiée dans la prestigieuse revue scientifique Human-Computer Interaction,
des chercheurs ont étudié les interactions entre différents comptes Twitter,
notamment les retweets des uns et des autres.
Clairement, on observe deux clans,
qui correspondent aux deux partis politiques dominants outre-Atlantique.
Mais surtout, on voit que les trolls russes, ici en rouge dans l'image,
n'ont pas du tout cherché à défendre un clan plutôt que l'autre.
Ils sont en fait infiltrés au coeur des deux clans,
actifs dans l'amplification des contenus les plus radicaux de chaque clan.
https://dl.acm.org/doi/10.1145/3274289 

Imaginez ça. Vous défendez le respect des forces de l'ordre,
ou peut-être que vous défendez plutôt les droits des noirs américains et des minorités.
Et vous croyez avoir énormément de soutiens dans votre démarche...
mais vos plus fervents soutiens sont en fait... des agents russes !
Mais pourquoi des agents russes cherchent-ils alors à amplifier notre voix ?
Et pourquoi amplifient-ils aussi le camp opposé ?
Mais surtout, ne faut-il pas y voir une raison de douter de nos prises de position ?

En fait, l'intérêt d'amplifier les positions les plus radicales des deux clans est double.
D'un côté, cela augmente la visibilité de ces positions, et permet donc leur diffusion.
De l'autre, de manière plus insidieuse et peut-être beaucoup plus dangereuse,
cela radicalise les créateurs de contenus,
qui voient leurs prises de positions les plus haineuses être beaucoup plus virales,
et donc plus lucratives,
notamment pour ceux qui vivent de leur production de contenus informationnels.

En tout cas, dix ans après ces attaques informationnelles,
force est de reconnaître que l'objectif de polarisation des démocraties a été atteint.
Côté US, Biden et Trump ont adopté les langages les plus clivants de l'histoire,
et sont tout deux devenus détestés par le clan opposé.  
https://academic.oup.com/view-large/figure/489131311/pgae431f5.jpg   
https://academic.oup.com/pnasnexus/article/3/10/pgae431/7814873 

Et ça, surtout dans un système à 2 parti comme aux US,
ça a pour conséquence que pour plaire à son électorat,
un candidat a en fait tout intérêt à exagérer, stigmatiser et moquer le clan opposé,
et que l'électorat pardonnera le manque de cohérence de son candidat,
pourvu qu'il critique suffisamment le clan opposé.

Dans d'autres démocraties où le scrutin n'est pas aussi dangereusement pourri
que le scrutin uninominal à 1 tour ou que ses variantes comme celles adoptées aux États-Unis,
la polarisation n'en reste pas moins extrêmement problématique,
comme on le voit si clairement en France depuis un an.
Chaque parti politique est tellement fonde sur une haine des autres partis,
qu'il est devenu impossible de faire collaborer même des partis peu éloignés,
à l'instar du Nouveau Front Populaire déjà largement fissuré.
Sauf que le NFP, c'est juste la gauche.
Aujourd'hui, pour avoir l'adhésion d'une majorité de l'Assemblée,
voire d'une majorité écrasante de l'Assemblée,
cela semble peine perdue,
tant les partis de gauche refusent de s'allier avec la Macronie, la droite et l'extrême-droite,
et vice-versa.

En particulier, dans nos écosystèmes informationnels devenus ultra-cloisonnés et personnalisés,
nous avons abandonnés les communs informationnels et idéologiques.
Et juste pour clarifier, cela ne veut pas dire qu'on n'est pas exposés aux idées contraires ;
en fait, on y est même probablement plus exposés que jamais.
Mais la manière dont on y est exposés, c'est en étant entourés de critiques acerbes du clan opposé,
prêts à se révolter à la moindre virgule mal placée,
et qui nous encourage ainsi, consciemment ou non,
à ne jamais accepter aucune concession pour ne pas envisager un "pacte avec le diable".
Pire, tout commun qu'on pourrait avoir avec le diable peut alors être vu comme une faiblesse,
dont il serait urgent de se débarasser.

Et ça, c'est l'une des facettes les plus dangereuses de la crise informationnelle.
Car en banalisant un écosystème où il est devenu normal de penser que
la majorité, voire la quasi-totalité de nos concitoyens, sont des diables à stigmatiser,
on garantit une radicalisation de leurs courants de pensée,
on renforce la paralysie institutionnelle
et, surtout, on décrédibilise la possibilité d'une démocratie fonctionnelle.

Bref. Il y a clairement beaucoup de mésinformations à corriger.
Mais avant de dépenser notre attention et celle de nos concitoyens à faire ce débunking,
je vous invite à d'abord vous poser la question suivante.
Est-ce que donner de l'attention à cette mésinformation est vraiment productif ?
Ou est-ce que ce n'est pas une communication qui va en fait nuire à la crise informationnelle
et à la perte de communs idéologiques dans nos sociétés divisées ?


## Les contre-sommets de l'IA

Pour rendre ces réflexions beaucoup plus concrètes encore,
je vous invite à nous intéresser au cas particulier des contre-sommets de l'IA,
qui ont eu lieu à Paris en février dernier.
Pour rappel, la France avait alors organisé un sommet de l'action de pour l'IA,
qui avait beaucoup trop tendance à célébrer l'IA et sa dérégulation,
en tout cas aux yeux de nombreux chercheurs et de nombreux défenseurs des droits humains.

Du coup, beaucoup d'organisations diverses et variées
ont alors cherché à organiser des événements parallèles,
qui eux cherchaient au contraire à souligner l'urgence
à valoriser l'éthique et la sécurité dans le domaine de l'IA.

Il y a notamment eu la première conférence de
l'Association Internationale pour une IA sûre et éthique,
le Forum des Solutions pour une IA compatible avec l'humanité,
les tables rondes du 404 Planet Not Found,
et bien d'autres événements encore.

Sauf que, clairement, ces différents événements ne tiraient pas toujours dans le même sens.
Et même quand il cherchait avant tout à fédérer,
il suffisait d'écouter les intervenants pour ressentir d'énormes tensions au sein des participants.
En fait, cela fait maintenant une décennie que deux clans se sont formés dans le monde académique,
avec d'un côté "l'éthique de l'IA", ou AI Ethics,
qui priorise des sujets comme les biais algorithmiques, les travailleurs du clic et le changement climatique,
avec des figures dominantes comme Margaret Mitchell, Kate Crawford ou Maria Ressa,
et de l'autre "la sûreté de l'IA", ou AI Safety,
qui priorise les risques existentiels associés à l'émergence d'une superintelligence,
avec des chercheurs comme Geoffrey Hinton, Yoshua Bengio et Stuart Russell.

Et vraiment, s'il y a un sujet qui divise,
le sujet qui est l'équivalent dans ces communautés
de l'immigration ou de l'antisémitisme dans la politique française,
c'est bien celui de l'intelligence des IA.
D'un côté, certains vont nier toute intelligence de ces systèmes,
en insistant sur le fait que le danger est au contraire de confier des tâches critiques à ces systèmes
alors qu'on sait qu'elles font énormément de bêtises.
De l'autre, il y a ceux qui insistent sur les facultés spectaculaires de ces algorithmes,
et sur le danger que ces facultés représentent en cas de mésalignement de leur fonction objectif.

Mais surtout, plutôt que de parler des impacts et des menaces contre lesquels il faut réagir,
ou de débattre des solutions qu'il faut développer et déployer pour éviter une catastrophe,
trop souvent, les discussions dérivent sur la définition du mot "intelligence",
voire sur l'existence d'un "je ne sais quoi" 
qui distinguerait ou non l'intellect humain des machines.
Pour quelqu'un comme moi déjà terrifié par l'impact qu'ont déjà eu les IA depuis une décennie
sur le déclin généralisé des démocraties 
et l'augmentation des tensions géopolitiques entre superpuissances,
ainsi que par les conséquences probables de la poursuite 
de la sur-optimisation de ces systèmes,
surtout en l'absence de garde-fous comme c'est le cas aujourd'hui,
j'ai carrément l'impression d'être au milieu d'une pièce en feu,
où on préfère s'écharper sur la nature profonde du feu,
plutôt qu'appeler les pompiers et fuire la maison.

Mais surtout, si j'étais l'un des géants des technologies de l'information,
ou l'un des techo-enthousiastes qui veulent accélérer le développement technologique sans régulation,
j'adopterais très clairement la stratégie des trolls russes aux États-Unis en 2016,
ou celle du vice-président des États-Unis à la conférence de Munich sur la sécurité :
j'entretiendrai volontiers le feu de la division chez ceux qui veulent me réguler,
en amplifiant à la fois les discours qui disent "l'intelligence artificielle n'existe pas"
et ceux qui disent "la superintelligence est le plus grand des dangers".
Car dans cette cacophonie,
je trouverai beaucoup moins de résistance à l'adoption de mes produits,
aussi bien chez le grand public, dans les entreprises et vis-à-vis des régulateurs.

Et en pratique, c'est exactement ce qu'on a observé.
Le lobbying intense des géants du numérique a affaibli drastiquement les régulations européennes,
et s'est même interposé pour empêcher l'application des lois déjà existantes,
comme par exemple celles sur les droits d'auteur et sur le RGPD,
y compris malgré les confessions d'infraction par le PDG d'OpenAI.
Ainsi, si l'Italie a un temps osé envisager asujettir le numérique à l'État de droit,
elle s'est mystérieusement vite rétractée.


## L'espace multidimensional du dialogue

En politique, le dialogue est tellement tombé dans une caricature de débat unidimensionnel 
qu’on a donné les noms de gauche et de droite aux deux clans du débats, 
mais aussi d’extrême-gauche et d’extrême-droite 
pour les positions les plus extrêmes sur le spectre politique. 
Et ça, c’est très bizarre à y réfléchir. 
Est-ce que, quel que soit le sujet, 
les positions défendues par l’extrême-gauche sont plus extrêmes que celles de la gauche, 
et celles de l’extrême-droite sont plus extrêmes que celle de la droite ?

Même en prenant quelques sujets au coeur du dialogue politique, 
l’axe unidimensionnel est loin d’être si évident. 
Wikipedia affirme que la gauche prône le progressisme et le changement social, 
là où la droite est en faveur du conservatisme et des traditions. 
Mais si on veut conserver l’indépendance de la justice 
et défendre la tradition du respect de l’État de Droit, 
est-ce qu’on est vraiment plus à droite ?

De même, selon Wikipedia, la gauche cherche à produire une société plus égalitaire, 
que cette égalité soit économique, politique, ou sociale. 
La droite va plutôt privilégier la hiérarchie et le mérite. 
Pourtant la structure même de La France Insoumise, toujours selon Wikipedia, 
est extrêmement fondée sur la hiérarchie. 
Et on peut même douter du fait que le centre privilégie davantage l’égalité que la droite ; 
pour rappel, un Premier Ministre de droite, Michel Barnier, 
a proposé la taxation des super riches 
que les gouvernements macronistes n’ont jamais proposée.

Pourtant, malgré le manque de cohérence de la projection unidimensionnelle de la politique,
un individu qui prend certaines bonnes idées de différentes offres reste souvent vu 
comme un individu apolitique ou dépolitisé, 
comme si la politique nécessitait une prise de position bien définie 
sur l’axe unidimensionnel de la politique.

Et c’est bien dommage, car les considérations dont il faut tenir compte 
pour gouverner au mieux nos démocraties sont extrêmement multidimensionnelles : 
inégalités, souveraineté, numérique, énergie, fiscalité, services publics, géopolitique, écologie,
santé publique, bien-être mental, criminalité, organisation des institutions publiques…
Le nombre de dimensions est absolument monumental, 
surtout si pour chaque sujet, on considère aussi l’éventail des stratégies envisageables 
pour piloter la réponse à des manquements.

Clairement, réduire toute cette complexité à une ligne gauche-droite appauvrit le débat.
Mais c’est même pire que cela.
Alors qu’il y a très certainement un grand nombre de sujets 
sur lesquels la population française a un avis consensuel 
comme la souveraineté numérique, la transition énergétique 
ou l’amélioration du bien-être mental, notamment chez les jeunes, 
en projetant ces sujets aussi sur l’axe gauche-droite de la politique, 
on en vient des créer des tensions factices qui n’auraient peut-être pas émergé 
si on n’avait pas effectué cette projection, 
et on peut alors bloquer des initiatives en fait assez consensuelles, 
à l’instar de l’idée de taxation des super riches de Michel Barnier.

En fait, certains partis politiques ont beaucoup à gagner 
à projeter systématiquement tout dialogue sur l’axe le plus polarisation, 
à l’instar de l’extrême-droite qui va vouloir ramener systématiquement le sujet de l’immigration, 
car celui-ci exacerbera les tensions, amplifiera la haine dans le débat, 
et appauvrira toutes autres considérations, 
en projetant très clairement le débat sur un axe unidimensionnel gauche-droite ; 
sans compter que plus un débat est clash, plus il sera amplifié par les IA de recommandation, 
et plus l’effet d’exposition répétée rendra l’extrême-droite populaire aux yeux de beaucoup…

En fait, même dans le cas du débat AI Ethics versus AI Safety, 
il y a une tendance à projeter la discussion selon l’axe gauche-droite, 
avec typiquement l’AI Ethics à gauche et l’AI Safety à droite, 
notamment parce que, historiquement, l’AI Safety était associé 
à de nombreux patrons des industries de la technologie, 
comme Elon Musk et Sam Altman, 
même si ces derniers sont en fait détestés de beaucoup de membres du groupe “AI Safety”.
Et du coup, en plus d’appauvrir le débat, ce réflexe peut surtout le polariser davantage, 
et donner l’impression que les positions des deux clans sont antagonistes et irréconciliables.

Mais donc, peut-on encore avoir des débats dans toutes les dimensions 
de l’espace multidimensionnel des sujets politiques, 
sans que ceux-ci soient systématiquement appauvris 
par une projection sur la ligne gauche-droite ?


## Les résultats de notre consultation Polis

Très rapidement, Jean-Lou Fourquet alias Après La Bière et moi, 
on a voulu explorer toutes les dimensions du débat sur la régulation des IA, 
au moins au sein des communautés des contre-sommets de l’IA.
Et pour y parvenir, on a utilisé ce qui nous semble être 
le meilleur outil librement disponible à ce jour, à savoir la plateforme Polis.

Le principe de Polis est extrêmement simple : 
tout participant peut faire des propositions, sous la forme d’un court message, 
puis il peut évaluer les propositions des autres participants, 
avec un like, un dislike ou un “je passe”.
En gros, Polis permet ainsi d’effectuer un sondage sur plusieurs propositions, 
mais avec la possibilité pour la communauté sondée de choisir les propositions évaluées.

Les données sont ensuite publiques, et peuvent être analysées par n’importe qui.
Mais surtout, la plateforme Polis propose certaines analyses des résultats, 
qui vont à la fois chercher à cartographier les différents sous-groupes de pensée 
et les points de convergence entre tous les sous-groupes.

En fait, techniquement parlant, Polis utilise une analyse par composante principale, 
qui revient à littéralement projeter les débats dans un espace de plus petite dimension.
Par défaut dans Polis, la discussion est projetée dans l’espace de dimension 2
de plus forte polarisation,
ce qui est un poil plus complexe que la projection unidimensionnelle.
Mais en principe, on pourrait projeter la discussion dans n’importe quel espace.

L’avantage de cette projection, c’est ensuite surtout de permettre une visualisation, 
une sorte de cartographie des différents sous-groupes de la consultation.
Dans le cas de la consultation, on a obtenu 2 groupes, 
un grand groupe de 148 participants et un petit groupe de 16 participants.
On peut voir que ces 16 participants peuvent être qualifiés de “AGI”,
puisqu’ils ont la spécificité de dénigrer le danger des IA de recommandation, 
et considèrent que le danger des IA est indépendant de leurs concepteurs.

Et là, vous avez peut-être dit que 
cette ségrégation des participants en 2 groupes de tailles si différentes est bizarre.
Pourquoi isoler 16 participants et laisser un gros bloc de 148 participants ?

Eh bien, c’est vraiment à cause du choix discutable 
d’algorithme de regroupement des participants par Polis.
En fait, si on dit beaucoup de bien de Polis en temps général, 
il y a en fait de quoi être très critique du projet, 
qui pendant longtemps n’était pas open source et libre 
(il ne l’est devenu que sous la pression d’Audrey Tang, 
alors future ministre du numérique de Taïwan), 
et qui n’est toujours pas très accueillant des propositions d’amélioration.

Mais du coup, faute de mieux, j’ai joué un peu avec les données dans mon coin,
avec d’autres algorithmes de créations de groupes – 
on parle de clustering dans le domaine.
Et j’ai construit un clustering en 5 groupes, de tailles respectives 120, 31, 14, 8 et 6.

Les clusters :
{32,67,132,37,38,167,72,104,105,174,79,83,117,54},
{1,2,3,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,25,28,29,33,34,35,36,41,43,44,45,46,49,51,52,55,56,57,61,62,63,65,66,68,69,74,75,76,77,81,84,85,87,88,89,91,92,93,94,95,96,97,98,100,101,102,106,107,110,112,114,116,118,119,120,121,122,124,125,126,127,128,129,130,133,135,136,138,140,141,142,143,145,146,147,148,149,150,151,152,153,154,155,158,159,161,162,163,164,165,166,168,169,171,172,176,177,178}, {0,134,144,24,26,157,160,39,40,42,170,173,47,48,175,53,58,59,60,70,73,78,90,99,103,108,109,111,113,115,123},
{71,80,82,86,27,156,30,31},
{64,131,4,137,139,50}

Le plus gros groupe considère que les IA de recommandation sont plus dangereuses
que les cyberattaques et les attaques bioterrorisme facilitées par l’IA, 
et est plus en désaccord que les autres groupes sur le fait que 
les IA plus éthiques seront moins utilisées.

Le groupe à 31 membres se dégagent nettement des autres 
par sa priorisation de la défense des enfants, des IA de recommandation,
du danger à laisser le contrôle des IA aux mains de techno-oligarques
et des enjeux écologiques.

Le groupe à 14 membres lui pourraient être qualifié de techno-optimistes.
Ils nient les risques de perte de contrôle et l’intérêt de ralentir le développement technologique.

Enfin, les deux derniers groupes, à 8 et 6 membres, 
semblent être plus ou moins le groupe AGI identifié par Polis,
avec pour différence le fait que le groupe à 8 membres est convaincu 
que les IA génératives sont beaucoup plus dangereuses que les IA de recommandation 
et qu’il faut urgemment mettre pause au développement des IA.
Le groupe à 6 membres lui se distinguent notamment 
de sa dépriorisation des enjeux écologiques et de la protection des enfants.

À noter qu’il faut se méfier des tailles respectives des groupes.
Bien sûr, elles dépendent avant tout du taux de participation des différentes communautés.
Et en l'occurrence, la consultation s’est surtout bien diffusée via l’Association Tournesol, 
ce qui explique pourquoi le groupe qui priorise les IA de recommandation est aussi grand.
Pas sûr qu’il le restera, si on se met à sonder d’autres populations.

OK, on a donc clairement des divisions marquées parmi les participants, 
et on aurait pu en rester là.
En fait, cette cartographie seule, si elle est intéressante pour identifier des forces en présence, 
elle est aussi très peu fructueuse pour les collaborations.

En fait, l’aspect le plus intéressant de Polis,
 c’est davantage la fonctionnalité “group-informed consensus”, 
qui revient à projeter l’espace de discussion dans les directions consensuelles 
relativement aux différents groupes présents.

Vu la discussion qu’on a eu jusque là, 
on pourrait croire qu’il y a peu de chances de trouver des points de convergence 
entre toutes ces différentes communités.
Détrompez-vous !

Tous les groupes, y compris les technophiles et les groupes AGI, 
veulent beaucoup plus de collaborations internationales en sécurité et en éthique de l’IA, 
ainsi que des régulations de l’IA et de l’éducation des citoyens.
Tous sont aussi très préoccupés par le cybercrime et la désinformation de masse, 
et par le fait que les IA génératives renforcent ces risques.
Enfin, tous sont alertés par les dangers des conflits d’intérêt, 
et veulent un soutien public pour la recherche sur la sécurité de l’IA.
Ça fait beaucoup de points d’accord entre toutes ces communautés !

Peut-être celui qui m’intéresse particulièrement à titre personnel, 
à travers ces communautés, 
il est consensuel de permettre à d’autres entitiés (médias, universités, citoyens…) 
de recommander des contenus numériques.
Et oui, parce que, ça, c’est justement le rôle du projet Tournesol.


## Conclusion

À travers l’exemple concret de la consultation que Jean-Lou et moi avons menée, 
j’espère vous avoir montré tout l’intérêt d’explorer toutes les dimensions d’un débat, 
et pas juste celles que la ligne politique gauche-droite impose, 
ou celles que l’exigence de viralité sur le web nous invite à adopter ; 
qui clairement va nous encourager à nous battre sur des sujets clivants, 
à l’instar du débat sur l’intelligence en IA.

Par ailleurs, c’est important de noter que 
les consensus selon certaines directions peuvent être des consensus radicaux, 
et non pas des compromis mous comme on pourrait le croire.
Trop souvent, dans nos sociétés, on a tendance à survaloriser le dissensus, 
comme si le progrès politique nécessitait forcément d’en venir à un match de boxe, 
et que la position à adopter sera celle du plus fort.
Mais en plus de forcer des compromis, 
cette approche peut surtout exacerber des tensions, 
et pousser les prochains débats à être projetés 
sur des dimensions de discussions passées.

Bien sûr, il ne faut pas perdre de vue les différences de rapports de forces , 
et ce que cela implique pour les directions de désaccord.
Mais dans un monde qui accélère, avec l’actualité débordante qu’est la nôtre, 
s’attarder sur ces désaccords, c’est surtout gaspiller de précieuses ressources, 
en particulier des ressources attentionnelles aujourd’hui très rares, 
et ne pas les utiliser pour avancer rapidement dans la protection de nos démocraties.

Et ce qu’on dit là du débat démocratique n’est bien sûr pas restreint à la démocratie.
Dans toutes nos discussions, y compris entre conjoints, avec des amis ou en famille,
il y a toujours des sujets de désaccord, 
c’est-à-dire des directions de l’espace de discussion qui sont vouées à attiser des tensions, 
et dont la seule issue envisageable semble le compromis, 
voire le constat d’une distance irréconciliable selon cet axe.

Et il en va de même dans tous les projets, y compris en entreprise.
D’ailleurs, justement, Jean-Lou alias Après La Bière a lancé Lyfe Catalyst, 
une entreprise pour accompagner des organisations 
dans la recherche des directions fructueuses de dialogue.
Et dans son expérience, clairement, ça marche. 
Et ça marche même extrêmement bien pour prioriser les tâches organisationnelles.
Donc je vous invite vraiment à le contacter, 
si vous voulez tester ces solutions de délibérations multidimensionnelles participatives 
dans vos organisations professionnelles.

Mais avant de conclure, j’insiste sur le fait que les solutions techniques actuelles 
pour explorer ces espaces de discussion collectivement sont encore très insatisfaisantes.
Comme on l’a vu, la solution Polis est fonctionnelle, mais très limitée, 
et s’appuie sur des algorithmes d’analyses de données très discutables.
Je vous mets en commentaire un Jupyter Notebook où j’ai un peu généralisé leurs solutions.
Mais il faudrait en faire beaucoup plus, 
aussi bien en termes d’IA de priorisation de l’information 
qu’en termes d’interfaces graphiques, 
pour faciliter l’exploration collective de l’espace multidimensionnelle politique.

Avec l’espoir, à termes de trouver des façons de tourner les débats 
qui mettent beaucoup de gens d’accord, aboutissent à des mesures concrètes 
et surtout renforcent nos systèmes démocratiques.
Et pour tout ça, je vous invite à aller voir la vidéo de Jean-Lou sur sa chaîne, 
qui en parle beaucoup plus en détails.
