# Programmer la morale ?

Certains parmi vous pourraient y voir un oxymore.
La morale semble être un sujet de sciences humaines,
et on pourrait vouloir affirmer qu'elle doit être le monopole de l'humain.
Tandis que les technologies sont des objets froids, sans émotion,
qui ne devraient pas être la source d'une quelconque éthique.

Cependant, on va voir que la philosophie morale avait en fait,
à bien des égards,
déjà inventé les grands paradigmes de la programmation.
Après tout, définir précisément ce qui est moral,
cela revient à définir une méthode pour déterminer ce qui est doit être fait,
et ce qui ne devrait pas être fait ;
or comme on l'a vu, méthode et algorithme, ce sont des synonymes.

Mieux encore, il y a des allers-retours fascinants à explorer
à l'interface entre philosophie morale et programmation,
mais aussi entre sciences cognitives et interfaces homme-machine,
ou encore entre droit et scrutin,
que je vous propose de détailler un peu aujourd'hui.

Enfin, si vous suivez cette chaîne, 
vous savez certainement que 
les algorithmes ont désormais des conséquences sociétales majeures,
et qu'il est donc urgent d'y inclure des considérations morales.


## Déontologie et programmation explicite

## Utilitarisme et apprentissage par renforcement

## Éthique de la vertue et pré-entraînement

## Exemplarité et apprentissage supervisé

## Scrutins et élicitation des préférences

## Liberté de la presse et volition

« Quand j'étudiais la géométrie, 
j'étais plus intéressé par la manière dont les preuves étaient découvertes
que par les théorèmes eux-mêmes.
Et de même, en sciences, j'étais plus intéressé par la manière 
dont les choses étaient découvertes
que par les contenus des découvertes.
L'Oeuf Doré n'était pas aussi excitant que l'oie qui l'avait pondu. »

Ces mots nous viennent du génialissime Ray Solomonoff,
cet informaticien dont j'ai beaucoup parlé dans ma série sur le bayésianisme,
ainsi que dans mon premier livre sur la formule du savoir
et l'approche probabiliste de l'épistémologie.
Et je dois bien dire que le Lê du passé était lui aussi absolument fasciné
par le moteur des découvertes scientifiques,
et surtout sur la manière de déterminer 
sur une théorie devait être célébrée par la communauté scientifique,
et non pas rejetée au même rang que les théories du complot.

Mais depuis quelques dernières années, 
il y a une autre épistémologie qui me fascine bien plus encore,
à savoir l'épistémologie d'une philosophie morale collective dans un contexte adversarial.
Ou dit plus simplement :
plutôt que de chercher à comprendre et justifier telle ou telle position morale,
comment pourrions-nous déterminer collaborativement 
les positions et les actions que nous devrions collectivement adopter,
en particulier vis-à-vis des communs dont nos survies individuelles dépendent ?
Et en particulier, comment y parvenir de manière pragmatique,
dans le monde dans lequel on vit,
en tenant par exemple en compte des moyens monumentaux investis
pour influencer et déformer la délibération publique ?

La question du "comment", c'est vraiment le sujet du constructivisme moral.
Selon ce courant de pensée de la philosophie morale,
ou plutôt de la méta-éthique,
ce qui détermine si un jugement est moral,
c'est avant tout si ce jugment découle d'une construction raisonnable.



